{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_images(file,image_size,color):\n",
    "\n",
    "    images = []\n",
    "    for img in os.listdir(file):\n",
    "\n",
    "        image = cv2.imread(file+\"/\"+img,color)\n",
    "     \n",
    "        image = cv2.resize(image,image_size)\n",
    "       \n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "def save_images(image_array,folder):\n",
    "    dir = os.path.join(os.getcwd(),folder)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    image_path = os.path.join(folder)  \n",
    "    for i in range(len(image_array)):\n",
    "        image_name = folder +\"_\"+str(i+1)+\".jpg\"\n",
    "        image_path = os.path.join(folder,image_name)  \n",
    "        cv2.imwrite(image_path,image_array[i])\n",
    "        \n",
    "\n",
    "def applyCanny(image_array,l_Threshold,h_threshold):\n",
    "    \n",
    "    canny_Array = np.zeros((image_array.shape[0],image_array.shape[1],image_array.shape[2])) # 3D array\n",
    "    for i in range(len(image_array)):\n",
    "        gauss_img = cv2.GaussianBlur(image_array[i],(5,5),1)  # Gaussian Blur before edge detection\n",
    "        canny_Array[i] = cv2.Canny(gauss_img,l_Threshold,h_threshold) # Canny Edge Detection\n",
    "    return canny_Array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crop_circle(image, circle):\n",
    "    \n",
    "    x, y, r = circle\n",
    "    mask = np.zeros_like(image)  \n",
    "    cv2.circle(mask, (x, y), r, (255, 255, 255), -1)\n",
    "    cropped = image * mask\n",
    "    cropped = cv2.resize(cropped,(128,128)) # 100,100\n",
    "    return cropped\n",
    "\n",
    "def calculateHOG(image_gray):\n",
    "    cell_size = 8 \n",
    "    block_size = 2 \n",
    "    bin_num = 9\n",
    "\n",
    "    x,y = image_gray.shape \n",
    "\n",
    "    image = image_gray.flatten()\n",
    "\n",
    "    n_cells_x = int(x // cell_size) # number of cells in x direction\n",
    "    n_cells_y = int(y // cell_size) # number of cells in y direction\n",
    "\n",
    "    n_blocks_y = n_cells_y - block_size + 1 \n",
    "    n_blocks_x = n_cells_x - block_size + 1\n",
    "\n",
    "    x_filter = np.array([-1,0,1]) \n",
    "    y_filter = x_filter.T\n",
    "\n",
    "    gx = (np.convolve(image,x_filter,mode=\"same\")).reshape(x,y) # gradient in x direction\n",
    "    gy = (np.convolve(image,y_filter,mode=\"same\")).reshape(x,y) # gradient in y direction\n",
    "\n",
    "   \n",
    "\n",
    "    magnitude = np.sqrt(gx**2 + gy**2)\n",
    "    orientation = np.arctan2(gy,gx) * (180/np.pi) # orientation in degrees\n",
    "\n",
    "    orientation  = orientation % 180 # orientation in range 0 to 180\n",
    "\n",
    "    bin_edges = np.linspace(0,180,bin_num + 1) # bin edges for histogram\n",
    "    #bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2 \n",
    "\n",
    "    hog_cells = np.zeros((n_cells_y,n_cells_x,bin_num)) \n",
    "\n",
    "    for i in range(n_cells_y): \n",
    "        for j in range(n_cells_x): \n",
    "            cell_mag = magnitude[i*cell_size : (i+1) * cell_size , j*cell_size : (j+1) * cell_size] # magnitude of cell\n",
    "            cell_ori = orientation[i*cell_size : (i+1) * cell_size , j*cell_size : (j+1) * cell_size] # orientation of cell\n",
    "\n",
    "            cell_bins = np.digitize(cell_ori,bin_edges)  # bin number of each pixel in cell\n",
    "\n",
    "            for k in range(1,bin_num +1 ):\n",
    "                hog_cells[i,j,k-1] = np.sum(cell_mag[cell_bins == k]) # sum of magnitude of pixels in each bin\n",
    "\n",
    "    \n",
    "    hog_blocks = np.zeros((n_blocks_y,n_blocks_x,block_size ** 2 *bin_num)) # hog features of each block\n",
    "    for i in range(n_blocks_y):\n",
    "        for j in range(n_blocks_x):\n",
    "            block_hog = hog_cells[i:i+block_size,j:j+block_size,:] \n",
    "            block_hog = block_hog.ravel() # flatten the block hog features\n",
    "\n",
    "            block_hog = block_hog / np.sqrt(np.sum(block_hog**2) + 1e-6) # normalizing the block hog features\n",
    "\n",
    "            hog_blocks[i,j,:] = block_hog\n",
    "\n",
    "    \n",
    "    hog_features = hog_blocks.ravel()\n",
    "    \n",
    "    return hog_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = read_images(\"Train\",(400,400),1)\n",
    "test_images_R = read_images(\"TestR\",(1500,1000),1)\n",
    "test_images_V = read_images(\"TestV\",(1500,1000),1)\n",
    "\n",
    "\n",
    "train_images_gray = read_images(\"Train\",(100,100),0) \n",
    "test_images_R_gray = read_images(\"TestR\",(300,200),0)\n",
    "test_images_V_gray = read_images(\"TestV\",(300,200),0)\n",
    "\n",
    "train_scale = 4\n",
    "test_scale = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_t = 50   # 50\n",
    "high_t = 150  # 80\n",
    "canny_train_images = applyCanny(train_images_gray,low_t,high_t)\n",
    "low_t = 0\n",
    "high_t = 15  \n",
    "canny_test_images_R = applyCanny(test_images_R_gray,low_t,high_t)\n",
    "canny_test_images_V = applyCanny(test_images_V_gray,low_t,high_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hough_circle_transform(image, min_rad, max_rad, threshold, circle_num):\n",
    "    y, x = np.nonzero(image)  # Pixel coordinates of edges\n",
    "\n",
    "    # Accumulator array to store votes\n",
    "    accumulator_arr = np.zeros((max_rad, image.shape[0], image.shape[1]))\n",
    "\n",
    "    theta = np.arange(0, 2 * np.pi, np.pi / 180)\n",
    "    sin = np.sin(theta)\n",
    "    cos = np.cos(theta)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for r in range(min_rad, max_rad):  # Since radius is unknown, loop is created for each radius value.\n",
    "            a = (x[i] - r * cos)\n",
    "            b = (y[i] - r * sin)\n",
    "            a = a.astype(int)\n",
    "            b = b.astype(int)\n",
    "\n",
    "            valid = np.where((a >= 0) & (a < image.shape[1]) & (b >= 0) & (b < image.shape[0]))\n",
    "\n",
    "            a = a[valid]\n",
    "            b = b[valid]\n",
    "\n",
    "            # Vote\n",
    "            accumulator_arr[r, b, a] += 1\n",
    "\n",
    "    circles = np.where(accumulator_arr > threshold)  # Find circles with votes greater than threshold\n",
    "\n",
    "        # Non-maximum suppression\n",
    "    sorted_indices = np.argsort(accumulator_arr[circles], axis=None)[::-1]\n",
    "    sorted_circles = (circles[0][sorted_indices], circles[1][sorted_indices], circles[2][sorted_indices])\n",
    "\n",
    "    selected_circles = []\n",
    "    for i in range(len(sorted_indices)):\n",
    "        r = sorted_circles[0][i]\n",
    "        x = sorted_circles[1][i]\n",
    "        y = sorted_circles[2][i]\n",
    "\n",
    "        overlap = False\n",
    "        for selected_circle in selected_circles:\n",
    "            dist = np.sqrt((x - selected_circle[0]) ** 2 + (y - selected_circle[1]) ** 2)\n",
    "            if dist < selected_circle[2] or dist < r:\n",
    "                overlap = True\n",
    "                break\n",
    "\n",
    "        if not overlap:\n",
    "            selected_circles.append((x, y, r))\n",
    "\n",
    "        if len(selected_circles) >= circle_num:\n",
    "            break\n",
    "\n",
    "    x = [circle[0] for circle in selected_circles]\n",
    "    y = [circle[1] for circle in selected_circles]\n",
    "    radius = [circle[2] for circle in selected_circles]\n",
    "\n",
    "    return list(zip(radius, x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. image completed.\n",
      "2. image completed.\n",
      "3. image completed.\n",
      "4. image completed.\n",
      "5. image completed.\n",
      "6. image completed.\n",
      "7. image completed.\n",
      "8. image completed.\n",
      "9. image completed.\n",
      "10. image completed.\n",
      "11. image completed.\n",
      "12. image completed.\n",
      "13. image completed.\n",
      "14. image completed.\n",
      "15. image completed.\n",
      "16. image completed.\n",
      "17. image completed.\n",
      "18. image completed.\n",
      "19. image completed.\n",
      "20. image completed.\n",
      "21. image completed.\n",
      "22. image completed.\n",
      "23. image completed.\n",
      "24. image completed.\n",
      "25. image completed.\n",
      "26. image completed.\n",
      "27. image completed.\n",
      "28. image completed.\n",
      "29. image completed.\n",
      "30. image completed.\n",
      "31. image completed.\n",
      "32. image completed.\n",
      "33. image completed.\n",
      "34. image completed.\n",
      "35. image completed.\n",
      "36. image completed.\n",
      "37. image completed.\n",
      "38. image completed.\n",
      "39. image completed.\n",
      "40. image completed.\n",
      "41. image completed.\n",
      "42. image completed.\n",
      "43. image completed.\n",
      "44. image completed.\n",
      "45. image completed.\n",
      "46. image completed.\n",
      "47. image completed.\n",
      "48. image completed.\n",
      "49. image completed.\n",
      "50. image completed.\n",
      "51. image completed.\n",
      "52. image completed.\n",
      "53. image completed.\n",
      "54. image completed.\n",
      "55. image completed.\n",
      "56. image completed.\n"
     ]
    }
   ],
   "source": [
    "circled_imgs_train = []\n",
    "circles_train = []\n",
    "for i in range(len(train_images)):\n",
    "    \n",
    "    circles = hough_circle_transform(canny_train_images[i],35,50,20,circle_num=1)\n",
    "    circles_train.append(circles)\n",
    "\n",
    "    for r in circles:\n",
    "        train_images[i] = cv2.circle(train_images[i],(r[2]*train_scale,r[1]*train_scale),r[0]*train_scale,(255,0,0),2)\n",
    "    circled_imgs_train.append(train_images[i])\n",
    "    print(f\"{i+1}. image completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. image completed.\n",
      "2. image completed.\n",
      "3. image completed.\n",
      "4. image completed.\n"
     ]
    }
   ],
   "source": [
    "circled_imgs_R = []\n",
    "circles_R = []\n",
    "for i in range(len(test_images_R)):\n",
    "    \n",
    "    circles = hough_circle_transform(canny_test_images_R[i],1,15,5,circle_num=20)\n",
    "    circles_R.append(circles)\n",
    "    for r in circles:\n",
    "        test_images_R[i] = cv2.circle(test_images_R[i],(r[2]*test_scale,r[1]*test_scale),r[0]*test_scale,(255,0,0),2)\n",
    "        \n",
    "    circled_imgs_R.append(test_images_R[i])\n",
    "    print(f\"{i+1}. image completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. image completed.\n",
      "2. image completed.\n",
      "3. image completed.\n",
      "4. image completed.\n",
      "5. image completed.\n",
      "6. image completed.\n",
      "7. image completed.\n",
      "8. image completed.\n",
      "9. image completed.\n",
      "10. image completed.\n",
      "11. image completed.\n",
      "12. image completed.\n"
     ]
    }
   ],
   "source": [
    "circled_imgs_V = []\n",
    "circles_V = []\n",
    "for i in range(len(test_images_V)):\n",
    "    circles = hough_circle_transform(canny_test_images_V[i],1,15,5,circle_num=20)\n",
    "    circles_V.append(circles)\n",
    "    for r in circles:\n",
    "        test_images_V[i] = cv2.circle(test_images_V[i],(r[2]*test_scale,r[1]*test_scale),r[0]*test_scale,(255,0,0),2)\n",
    "        \n",
    "    circled_imgs_V.append(test_images_V[i])\n",
    "    print(f\"{i+1}. image completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(circled_imgs_train,\"Train_Hough\")\n",
    "save_images(circled_imgs_R,\"TestR_Hough\")\n",
    "save_images(circled_imgs_V,\"TestV_Hough\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10kr_obverse', '10kr_obverse', '10kr_obverse', '10kr_obverse', '10kr_obverse', '10kr_reverse', '10kr_reverse', '10kr_reverse', '10kr_reverse', '10kr_reverse', '1kr_obverse', '1kr_obverse', '1kr_obverse', '1kr_obverse', '1kr_reverse', '1kr_reverse', '1kr_reverse', '1kr_reverse', '1TL_obverse', '1TL_obverse', '1TL_obverse', '1TL_obverse', '1TL_obverse', '1TL_reverse', '1TL_reverse', '1TL_reverse', '1TL_reverse', '1TL_reverse', '25kr_obverse', '25kr_obverse', '25kr_obverse', '25kr_obverse', '25kr_obverse', '25kr_reverse', '25kr_reverse', '25kr_reverse', '25kr_reverse', '25kr_reverse', '50kr_obverse', '50kr_obverse', '50kr_obverse', '50kr_obverse', '50kr_obverse', '50kr_reverse', '50kr_reverse', '50kr_reverse', '50kr_reverse', '50kr_reverse', '5kr_obverse', '5kr_obverse', '5kr_obverse', '5kr_obverse', '5kr_reverse', '5kr_reverse', '5kr_reverse', '5kr_reverse']\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for img_name in os.listdir(\"Train\"):\n",
    "    image_list = img_name.split(\"_\")\n",
    "    label_Name = image_list[0] + \"_\" + image_list[1]\n",
    "    labels.append(label_Name)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "\n",
    "for i in range(len(train_images_gray)): # For each train image (with class), tüm çemberlerin oluşturduğu hogları bul\n",
    "        if(len(circles_train[i]) == 0):\n",
    "                continue\n",
    "        cropped_img = crop_circle(train_images_gray[i],circles_train[i][0])\n",
    "        train_x.append(calculateHOG(cropped_img)) \n",
    "        train_y.append(labels[i])\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.SVC()\n",
    "classifier.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_images_V_gray)):\n",
    "        if(len(circles_V[i]) == 0):\n",
    "                continue\n",
    "        for circle in circles_V[i]:\n",
    "                cropped_img = crop_circle(test_images_V_gray[i],circle)\n",
    "                hog = calculateHOG(cropped_img)\n",
    "                prediction = classifier.predict([hog])\n",
    "                \n",
    "                test_images_V[i] = cv2.putText(test_images_V[i],prediction[0],(circle[2]*test_scale,circle[1]*test_scale),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "save_images(test_images_V,\"TestV_HoG\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images_R_gray)):\n",
    "        if(len(circles_R[i]) == 0):\n",
    "                continue\n",
    "        for circle in circles_R[i]:\n",
    "                cropped_img = crop_circle(test_images_R_gray[i],circle)\n",
    "                hog = calculateHOG(cropped_img)\n",
    "                prediction = classifier.predict([hog])\n",
    "                \n",
    "                test_images_R[i] = cv2.putText(test_images_R[i],prediction[0],(circle[2]*test_scale,circle[1]*test_scale),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "save_images(test_images_R,\"TestR_HoG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
